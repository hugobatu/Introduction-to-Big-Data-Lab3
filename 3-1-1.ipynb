{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification with Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1.1 Structured API Implementation (High-Level)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CreditCardFraud\").getOrCreate()\n",
    "\n",
    "data = spark.read.csv(\"creditcard.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Pre-processing and splitting data into train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import rand\n",
    "\n",
    "# filter class\n",
    "class_1_df = data.filter(col(\"Class\") == 1)\n",
    "class_0_df = data.filter(col(\"Class\") == 0)\n",
    "\n",
    "# count class value 1\n",
    "count_1 = class_1_df.count()\n",
    "# random with simlar amount in class value 0\n",
    "balanced_0_df = class_0_df.sample(False, fraction=(count_1 / class_0_df.count()), seed=2505)\n",
    "\n",
    "balanced_df = balanced_0_df.union(class_1_df)\n",
    "balanced_df = balanced_df.orderBy(rand())\n",
    "\n",
    "input_columns = [col_name for col_name in balanced_df.columns if col_name != \"Class\"]\n",
    "\n",
    "data = VectorAssembler(inputCols=input_columns, outputCol=\"Features\") \\\n",
    "           .transform(balanced_df).select(\"Features\", \"Class\")\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.75, 0.25], seed=2505)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Train the Logistic Regression model using MLlib:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 356:===========================>                          (12 + 12) / 24]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"Features\", labelCol=\"Class\")\n",
    "\n",
    "model = lr.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Evaluate the obtained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 382:===========================>                          (12 + 12) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9437\n",
      "AUC: 0.9816\n",
      "Precision: 0.9438\n",
      "Recall: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy = MulticlassClassificationEvaluator(labelCol=\"Class\", metricName=\"accuracy\").evaluate(predictions)\n",
    "\n",
    "auc = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\").evaluate(predictions)\n",
    "\n",
    "precision = MulticlassClassificationEvaluator(labelCol=\"Class\", metricName=\"weightedPrecision\").evaluate(predictions)\n",
    "\n",
    "recall = MulticlassClassificationEvaluator(labelCol=\"Class\", metricName=\"weightedRecall\").evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "pyspark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
